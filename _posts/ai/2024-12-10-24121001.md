---
title: "[PyTorch] 다중 선형 회귀"
excerpt: "데이터셋과 데이터로더로 다중 선형 회귀 구현"

categories:
  - AI

toc: false
toc_sticky: false

date: 2024-12-10
last_modified_at: 2024-12-10
---

> AI 스터디를 하며 '파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터비전 심층학습' 교재를 정리한 글입니다.  

## Dataset과 DataLoader

### 데이터셋(Dataset) 클래스

```python
class Dataset:
    def __init__(self, data, *arg, **kwargs):
        self.data = data

    def __getitem__(self, index):
        return tuple(data[index] for data in self.data.tensors)

    def __len__(self):
        return self.data[0].size(0)
```

### 데이터로더(DataLoader) 클래스

- batch_size, shuffle, num_workers 등 기능 제공
- batch_size: 전체 데이터 셋에서 배치 크기만큼 데이터 샘플을 나누어 모든 배치 대상으로 학습
  - 배치 크기가 1인 배치를 불완전한 배치(Incomplete Batch)라고 함
- shuffle: 데이터 순서 학습을 막기 위해 행 순서 변경
- num_workers: 데이터를 불러올 때 사용하는 프로세스 수

## 다중 선형 회귀

$$
\begin{align}
y_1 = w_1 x_1 + w_2 x_2 + b_1 \\
y_2 = w_3 x_1 + w_4 x_2 + b_2
\end{align}
$$

- x1, x2: 독립 변수  
- y1, y2: 종속 변수

- 모델 매개변수 형태

$$
\text{Weight} =
\begin{bmatrix}
w_1 & w_2 \\
w_3 & w_4
\end{bmatrix}
=
\begin{bmatrix}
1.7 & -0.8 \\
1.1 & 0.2
\end{bmatrix}
$$

$$
\text{Bias} =
\begin{bmatrix}
b_1 \\
b_2
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0
\end{bmatrix}
$$

- 10,000회 학습 결과

$$
\text{Weight} =
\begin{bmatrix}
w_1 & w_2 \\
w_3 & w_4
\end{bmatrix}
=
\begin{bmatrix}
0.8990 & -0.0235 \\
1.0535 & 0.2315
\end{bmatrix}
$$

$$
\text{Bias} =
\begin{bmatrix}
b_1 \\
b_2
\end{bmatrix}
=
\begin{bmatrix}
-0.6733 \\
0.0315
\end{bmatrix}
$$

```python
import torch
from torch import nn
from torch import optim
from torch.utils.data import TensorDataset, DataLoader
```

```python
train_x = torch.FloatTensor([
    [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]
])

train_y = torch.FloatTensor([
    [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]
])
```

```python
train_dataset = TensorDataset(train_x, train_y)  # TensorDataset: 기본 데이터세트 클래스를 상속받아 재정의한 클래스
train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)
```

```python
model = nn.Linear(2, 2, bias=True)
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.001)
```

```python
# 편향 제거
# model = nn.Linear(2, 2, bias=False)
# criterion = nn.MSELoss()
# optimizer = optim.SGD(model.parameters(), lr=0.001)
```

```python
for epoch in range(20000):
    cost = 0.0
    
    for batch in train_dataloader:  # 데이터로더를 반복하여 배치 반환
        x, y = batch
        output = model(x)
        loss = criterion(output, y)
    
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
        cost += loss

    cost = cost / len(train_dataloader)  # 오차 평균 계산

    if (epoch + 1) % 1000 == 0:
        print(f"Epoch : {epoch + 1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}")
```

### 출력

```
Epoch : 1000, Model : [Parameter containing:
tensor([[0.3475, 0.3747],
        [1.2057, 0.0328]], requires_grad=True), Parameter containing:
tensor([-0.4251,  0.4266], requires_grad=True)], Cost : 0.061
Epoch : 2000, Model : [Parameter containing:
tensor([[5.2809e-01, 2.8108e-01],
        [1.2682e+00, 3.9314e-04]], requires_grad=True), Parameter containing:
tensor([-0.6994,  0.3317], requires_grad=True)], Cost : 0.016
Epoch : 3000, Model : [Parameter containing:
tensor([[ 0.6202,  0.2335],
        [ 1.3000, -0.0161]], requires_grad=True), Parameter containing:
tensor([-0.8391,  0.2834], requires_grad=True)], Cost : 0.004
Epoch : 4000, Model : [Parameter containing:
tensor([[ 0.6671,  0.2093],
        [ 1.3163, -0.0244]], requires_grad=True), Parameter containing:
tensor([-0.9102,  0.2587], requires_grad=True)], Cost : 0.001
Epoch : 5000, Model : [Parameter containing:
tensor([[ 0.6911,  0.1970],
        [ 1.3246, -0.0287]], requires_grad=True), Parameter containing:
tensor([-0.9465,  0.2462], requires_grad=True)], Cost : 0.000
Epoch : 6000, Model : [Parameter containing:
tensor([[ 0.7032,  0.1907],
        [ 1.3288, -0.0309]], requires_grad=True), Parameter containing:
tensor([-0.9649,  0.2398], requires_grad=True)], Cost : 0.000
Epoch : 7000, Model : [Parameter containing:
tensor([[ 0.7094,  0.1875],
        [ 1.3309, -0.0320]], requires_grad=True), Parameter containing:
tensor([-0.9743,  0.2365], requires_grad=True)], Cost : 0.000
Epoch : 8000, Model : [Parameter containing:
tensor([[ 0.7126,  0.1858],
        [ 1.3320, -0.0326]], requires_grad=True), Parameter containing:
tensor([-0.9791,  0.2349], requires_grad=True)], Cost : 0.000
Epoch : 9000, Model : [Parameter containing:
tensor([[ 0.7142,  0.1850],
        [ 1.3326, -0.0329]], requires_grad=True), Parameter containing:
tensor([-0.9816,  0.2340], requires_grad=True)], Cost : 0.000
Epoch : 10000, Model : [Parameter containing:
tensor([[ 0.7150,  0.1846],
        [ 1.3329, -0.0330]], requires_grad=True), Parameter containing:
tensor([-0.9828,  0.2336], requires_grad=True)], Cost : 0.000
Epoch : 11000, Model : [Parameter containing:
tensor([[ 0.7154,  0.1843],
        [ 1.3330, -0.0331]], requires_grad=True), Parameter containing:
tensor([-0.9835,  0.2334], requires_grad=True)], Cost : 0.000
Epoch : 12000, Model : [Parameter containing:
tensor([[ 0.7157,  0.1842],
        [ 1.3331, -0.0331]], requires_grad=True), Parameter containing:
tensor([-0.9838,  0.2333], requires_grad=True)], Cost : 0.000
Epoch : 13000, Model : [Parameter containing:
tensor([[ 0.7158,  0.1842],
        [ 1.3331, -0.0331]], requires_grad=True), Parameter containing:
tensor([-0.9840,  0.2332], requires_grad=True)], Cost : 0.000
Epoch : 14000, Model : [Parameter containing:
tensor([[ 0.7158,  0.1842],
        [ 1.3331, -0.0331]], requires_grad=True), Parameter containing:
tensor([-0.9840,  0.2332], requires_grad=True)], Cost : 0.000
Epoch : 15000, Model : [Parameter containing:
tensor([[ 0.7158,  0.1841],
        [ 1.3331, -0.0332]], requires_grad=True), Parameter containing:
tensor([-0.9841,  0.2332], requires_grad=True)], Cost : 0.000
Epoch : 16000, Model : [Parameter containing:
tensor([[ 0.7159,  0.1841],
        [ 1.3331, -0.0331]], requires_grad=True), Parameter containing:
tensor([-0.9841,  0.2332], requires_grad=True)], Cost : 0.000
Epoch : 17000, Model : [Parameter containing:
tensor([[ 0.7159,  0.1841],
        [ 1.3331, -0.0331]], requires_grad=True), Parameter containing:
tensor([-0.9841,  0.2332], requires_grad=True)], Cost : 0.000
Epoch : 18000, Model : [Parameter containing:
tensor([[ 0.7159,  0.1841],
        [ 1.3331, -0.0331]], requires_grad=True), Parameter containing:
tensor([-0.9841,  0.2332], requires_grad=True)], Cost : 0.000
Epoch : 19000, Model : [Parameter containing:
tensor([[ 0.7159,  0.1841],
        [ 1.3331, -0.0331]], requires_grad=True), Parameter containing:
tensor([-0.9841,  0.2332], requires_grad=True)], Cost : 0.000
Epoch : 20000, Model : [Parameter containing:
tensor([[ 0.7159,  0.1841],
        [ 1.3331, -0.0331]], requires_grad=True), Parameter containing:
tensor([-0.9841,  0.2332], requires_grad=True)], Cost : 0.000
```