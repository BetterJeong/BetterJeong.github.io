---
title: "[PyTorch] 텍스트 데이터 증강(Text Data Augmentation)"
excerpt: "NLPAUG 라이브러리와 데이터 증강 클래스"

categories:
  - AI

toc: false
toc_sticky: false

date: 2024-12-31
last_modified_at: 2024-12-31
---

> AI 스터디를 하며 '파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터비전 심층학습' 교재를 정리한 글입니다.  

# 데이터 증강(Data Augmentation)

데이터가 가진 고유한 특징을 유지한 채 변형하거나 노이즈를 추가해 데이터셋 크기를 인위적으로 늘리는 방법  
기존 학습 데이터를 재가공해 원래 데이터와 유사하지만 새로운 데이터 생성  

## 텍스트 데이터

문서 분류, 요약, 문장 번역 등 데이터셋 크기를 쉽게 늘리기 위해 사용  
삽입, 삭제, 교체, 대체, 생성, 반의어, 맞춤법 교정, 역번역 등이 있음  

### 자연어 처리 데이터 증강(NLPAUG) 라이브러리  

간단한 코드 구성으로 데이터 증강을 적용할 수 있게 해줌  
문자, 단어, 문장에 대한 삽입, 삭제, 대체, 교체, 분할, 정렬, 자르기 기능 제공  
음성 데이터 증강도 지원  

```
pip install numpy requests nlpaug transformers sacremoses nltk
```

```python
import nlpaug.augmenter.word as naw
import nlpaug.augmenter.char as nac
```

```python
texts = [
    "Those who can imagine anything, can create the impossible.",
    "We can only see a short distance ahead, but we can see plenty there that needs to be done.",
    "If a machine is expected to be infallible, it cannot also be intelligent."
]
```

### 삽입 및 삭제

삽입: 의미 없는 문자나 단어 또는 문장 의미에 영향을 끼치지 않는 수식어 등을 추가하는 방법으로 기존 텍스트에 임의의 단어나 문자를 추가  
삭제: 임의의 단어나 문자 삭제  

너무 적은 양을 삽입하거나 삭제하면 과대적합, 반대로 너무 많은 양을 사용하면 데이터 품질 저하 발생  

```python
aug = naw.ContextualWordEmbsAug(model_path="bert-base-uncased", action="insert")  # 허깅페이스 활용, BERT를 통해 단어 삽입
```

```python
aug = nac.RandomCharAug(action="delete")  # 무작위 문자 삭제
```

```python
augmented_texts = aug.augment(texts)  # 데이터 증강

for text, augmented in zip(texts, augmented_texts):
    print(f"src: {text}")
    print(f"dst: {augmented}")
    print("------------------")
```

### 출력

```
src: Those who can imagine anything, can create the impossible.
dst: hse who can imagine nying, can cete the mpsible.
------------------
src: We can only see a short distance ahead, but we can see plenty there that needs to be done.
dst: We can oy see a ort disnc hea, but we can see plenty tre ta ees to be done.
------------------
src: If a machine is expected to be infallible, it cannot also be intelligent.
dst: If a maie is expected to be nllible, it cant ls be inliget.
------------------
```

### 교체 및 대체

교체: 단어나 문자의 위치 교환, 데이터 특성에 따라 의미가 잘못된 문장을 생성할 수 있으므로 주의  
대체: 임의의 단어나 문자로 바꾸거나 동의어로 변경, 데이터의 정합성(Consistency)이 어긋나지 않아 효율적, 조사가 어색해질 수 있어 주의  

```python
import nltk
nltk.download('averaged_perceptron_tagger')
```

```python
aug = naw.RandomWordAug(action="swap")  # 무작위로 단어 교체
```

```python
aug = naw.SynonymAug(aug_src="wordnet") # 단어 대체, 데이터베이스 내 유의어와 동의어로 변경하므로 본래 문맥과 전혀 달라질 수 있음
```

```python
augmented_texts = aug.augment(texts)  # 데이터 증강
```

```python
reserved_tokens = ["can", "can't", "cannot", "could"]

reserved_aug = naw.ReservedAug(reserved_tokens=reserved_tokens)  # 입력 데이터에 포함된 단어를 특정 단어로 대체
augmented_texts = reserved_aug.augment(texts)
```

### 출력

```
True
```

```
src: Those who can imagine anything, can create the impossible.
dst: Those who can imagine anything, can create the impossible.
------------------
src: We can only see a short distance ahead, but we can see plenty there that needs to be done.
dst: We can only see t short distance ahead, but we can see plenty there that needs to be done.
------------------
src: If a machine is expected to be infallible, it cannot also be intelligent.
dst: If n machine is expected to be infallible, it cannot also be intelligent.
------------------
```

### 역번역(Back-translation)

입력 테스트를 특정 언어로 번역하고 다시 본래의 언어로 번역  
번역 과정에서 원래 텍스트와 유사한 텍스트가 생성되어 패러프레이징(Paraphrasing) 효과  
번역 모델의 성능에 의존  

```python
back_translation = naw.BackTranslationAug(  # 두 개의 모델을 활용하므로 많은 리소스 소모
    from_model_name="facebook/wmt19-en-de",  # 입력 모델: 영어 -> 독일어
    to_model_name="facebook/wmt19-de-en"  # 출력 모델: 독일어 -> 영어
)

augmented_texts = back_translation.augment(texts)
```

```python
for text, augmented in zip(texts, augmented_texts):
    print(f"src: {text}")
    print(f"dst: {augmented}")
    print("------------------")
```

### 출력

```
src: Those who can imagine anything, can create the impossible.
dst: Anyone who can imagine anything can achieve the impossible.
------------------
src: We can only see a short distance ahead, but we can see plenty there that needs to be done.
dst: We can only look a little ahead, but we can see a lot there that needs to be done.
------------------
src: If a machine is expected to be infallible, it cannot also be intelligent.
dst: If a machine is expected to be infallible, it cannot be intelligent.
------------------
```

### 데이터 증강 클래스

| 방법            | 클래스                     | 지원 가능 동작                          |
|----------------|----------------------------|----------------------------------------|
| 오타 오류 증강 | `nac.KeyboardAug()`        | 대체(substitute)                       |
| 무작위 문자 증강 | `nac.RandomCharAug(action)` | 삽입(insert), 대체(substitute), 교체(swap), 삭제(delete) |
| 무작위 단어 증강 | `naw.RandomWordAug(action)` | 대체(substitute), 교체(swap), 삭제(delete), 자르기(crop) |
| 동의어 증강 | `nac.RandomCharAug(action)` | 워드넷(wordnet), 의역 데이터베이스(ppdb) |
| 예약어 증강 | `naw.SynonymAug(aug_src)`  | 대체(substitute)                       |
| 철자 오류 증강 | `naw.ReservedAug(reserved_tokens)` | 대체(substitute)                       |
| 상황별 단어 임베딩 증강 | `naw.SpellingAug()`      | 삽입(insert), 대체(substitute)         |
| 역번역 증강  | `naw.BackTranslationAug(from_model_name, to_model_name)` | 역번역       |
| 문장 요약 증강  | `nas.AbstSummAug(model_path="t5-base")` | 텍스트 요약                             |
